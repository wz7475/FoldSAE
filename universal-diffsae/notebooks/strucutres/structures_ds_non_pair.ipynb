{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6fc985",
   "metadata": {},
   "source": [
    "# Dataset for stride structures\n",
    "- found some previouly saved latents and structures\n",
    "- latents from pair SAE were randomly sampled, so information about token id was lost => impossible to map to index from stride sequence\n",
    "- final ds columns: **values, strucuture_id, token_id, timestep, secondary_struct, helix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:50:52.411400Z",
     "start_time": "2025-08-13T14:50:52.396548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "def run_stride(pdb_path: str, output_path: str, stride_path):\n",
    "    subprocess.run(\n",
    "        f\"{stride_path} -o {pdb_path} > {output_path}\",\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=30,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46d5fa",
   "metadata": {},
   "source": [
    "## generate stide outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a63ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:50:55.882780Z",
     "start_time": "2025-08-13T14:50:55.874362Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def parse_directory(dir_with_pdb: str, dir_for_stride, stride_binary: str) -> None:\n",
    "    os.makedirs(dir_for_stride, exist_ok=True)\n",
    "    for pdb_file in glob.glob(f\"{dir_with_pdb}/*.pdb\"):\n",
    "        base_name = os.path.basename(pdb_file)\n",
    "        stride_file_name = base_name.replace(\".pdb\", \".stride\")\n",
    "        stride_file = os.path.join(dir_for_stride, stride_file_name)\n",
    "        run_stride(pdb_file, stride_file, stride_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95af684",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_dir = \"/home/wzarzecki/ds_secondary_struct/structures\"\n",
    "stride_dir = \"/home/wzarzecki/ds_secondary_struct/stride\"\n",
    "stride_binary = \"/data/wzarzecki/SAEtoRuleRFDiffusion/stride/stride\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65f950f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:39:47.807799Z",
     "start_time": "2025-08-13T14:39:45.687828Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parse_directory(pdb_dir, stride_dir, stride_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a2b2240a3593e",
   "metadata": {},
   "source": [
    "## merge datasets\n",
    "from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379d71e73822a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:51:16.012756Z",
     "start_time": "2025-08-13T14:51:14.037714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzarzecki/miniforge3/envs/rf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['values', 'subcellular', 'solubility'],\n",
       "    num_rows: 187\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "example_ds = Dataset.load_from_disk(\n",
    "    \"/home/wzarzecki/ds_secondary_struct/latents/non_pair/1/xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a\")\n",
    "example_ds.set_format(\"torch\")\n",
    "example_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da418b40d2f05d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T14:42:38.322490Z",
     "start_time": "2025-08-13T14:42:38.252100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " 'subcellular': 'Nucleus',\n",
       " 'solubility': 'Soluble'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43359e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:01:52.202946Z",
     "start_time": "2025-08-13T15:01:52.184819Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def merge_datasets(base_dir: str, save_path: str):\n",
    "    merged_rows = []\n",
    "    for timestep_dir in sorted(os.listdir(base_dir)):\n",
    "        timestep_path = os.path.join(base_dir, timestep_dir)\n",
    "        if not os.path.isdir(timestep_path):\n",
    "            continue\n",
    "        for struct_id in sorted(os.listdir(timestep_path)):\n",
    "            struct_path = os.path.join(timestep_path, struct_id)\n",
    "            if not os.path.isdir(struct_path):\n",
    "                continue\n",
    "            try:\n",
    "                ds = Dataset.load_from_disk(struct_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {struct_path}: {e}\")\n",
    "                continue\n",
    "            df = ds.to_pandas()\n",
    "            df = df.drop(columns=[col for col in ['subcellular', 'solubility'] if col in df.columns], errors='ignore')\n",
    "            df['structure_id'] = struct_id\n",
    "            df['timestep_id'] = int(timestep_dir)\n",
    "            df['token_id'] = df.index\n",
    "            merged_rows.append(df)\n",
    "        print(f\"processed {timestep_dir}\")\n",
    "    if not merged_rows:\n",
    "        print(\"No datasets found to merge.\")\n",
    "        return\n",
    "    merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "    # 'values' column: if only one column left, rename it to 'values', else keep as is\n",
    "    value_cols = [col for col in merged_df.columns if col not in ['structure_id', 'timestep_id', 'token_id']]\n",
    "    if len(value_cols) == 1 and value_cols[0] != 'values':\n",
    "        merged_df = merged_df.rename(columns={value_cols[0]: 'values'})\n",
    "    merged_ds = Dataset.from_pandas(merged_df)\n",
    "    merged_ds.save_to_disk(save_path)\n",
    "    print(f\"Merged dataset saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb4e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_latents_dir = \"/home/wzarzecki/ds_secondary_struct/latents/non_pair\"\n",
    "merged_ds_dir = \"/home/wzarzecki/ds_secondary_struct/merged_latents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65001ed0c6e8874a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:08:30.874023Z",
     "start_time": "2025-08-13T15:01:56.922501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1\n",
      "processed 10\n",
      "processed 11\n",
      "processed 12\n",
      "processed 13\n",
      "processed 14\n",
      "processed 15\n",
      "processed 16\n",
      "processed 17\n",
      "processed 18\n",
      "processed 19\n",
      "processed 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (28/28 shards): 100%|██████████| 732450/732450 [01:35<00:00, 7683.99 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved to /home/wzarzecki/ds_secondary_struct/merged_latents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "merge_datasets(base_latents_dir, merged_ds_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95045fe3e1316991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:08:45.726971Z",
     "start_time": "2025-08-13T15:08:45.660053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84df148d2504ade916ced3689d64d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['values', 'structure_id', 'timestep_id', 'token_id'],\n",
       "    num_rows: 732450\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_ds = Dataset.load_from_disk(merged_ds_dir)\n",
    "merged_ds.set_format(\"torch\")\n",
    "merged_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a44638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:08:50.065695Z",
     "start_time": "2025-08-13T15:08:49.784416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " 'structure_id': 'xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a',\n",
       " 'timestep_id': tensor(1),\n",
       " 'token_id': tensor(0)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c28d9da6299d12",
   "metadata": {},
   "source": [
    "## add secondary structure labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ac987bbb0baf38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:14:02.249308Z",
     "start_time": "2025-08-13T15:14:02.233798Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "def parse_stride_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Parses a STRIDE file to extract secondary structure strings based on\n",
    "    the amino acid sequence location in corresponding 'SEQ' lines.\n",
    "    \"\"\"\n",
    "    structure_parts = []\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith(\"SEQ\"):\n",
    "                # Find the start index of the amino acid sequence.\n",
    "                # It's the first non-whitespace character after the initial residue number.\n",
    "                match = re.search(r'SEQ\\s+\\d+\\s+(\\S)', line)\n",
    "                if not match:\n",
    "                    continue\n",
    "                \n",
    "                start_index = match.start(1)\n",
    "\n",
    "                # Find the end index of the sequence.\n",
    "                # It's the last non-whitespace character before the final residue number.\n",
    "                match = re.search(r'(\\S)\\s+\\d+\\s*~*$', line)\n",
    "                if not match:\n",
    "                    continue\n",
    "                \n",
    "                end_index = match.start(1) + 1\n",
    "\n",
    "                # Check for the STR line immediately following the SEQ line\n",
    "                if i + 1 < len(lines) and lines[i+1].startswith(\"STR\"):\n",
    "                    str_line = lines[i+1]\n",
    "                    # Extract the structure part using the indices from the SEQ line\n",
    "                    structure_part = str_line[start_index:end_index]\n",
    "                    structure_parts.append(structure_part)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Stride file not found: {file_path}\")\n",
    "        return \"\"\n",
    "    return \"\".join(structure_parts)\n",
    "\n",
    "def add_secondary_struct_column(ds: Dataset, stride_dir: str) -> Dataset:\n",
    "    \"\"\"\n",
    "    Adds a 'secondary_struct' column to the dataset by mapping token_id to\n",
    "    secondary structure information from STRIDE files.\n",
    "    \"\"\"\n",
    "    stride_cache = {}\n",
    "\n",
    "    def get_secondary_structure(example):\n",
    "        structure_id = example['structure_id']\n",
    "        token_id = example['token_id']\n",
    "\n",
    "        if structure_id not in stride_cache:\n",
    "            stride_file_path = os.path.join(stride_dir, f\"{structure_id}.stride\")\n",
    "            stride_cache[structure_id] = parse_stride_file(stride_file_path)\n",
    "\n",
    "        full_ss_string = stride_cache[structure_id]\n",
    "\n",
    "        if token_id < len(full_ss_string):\n",
    "            label = full_ss_string[token_id]\n",
    "            return label if label.strip() != '' else None\n",
    "        return None\n",
    "\n",
    "    return ds.map(lambda example: {'secondary_struct': get_secondary_structure(example)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87fb92d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, '    E', 'H ')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_str = parse_stride_file(\"/home/wzarzecki/ds_secondary_struct/stride/xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a.stride\")\n",
    "len(stride_str), stride_str[:5], stride_str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00710691",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-08-13T15:14:06.394412Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7ad0ef40c24fbe8fdc5bd7ad90178e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['values', 'structure_id', 'timestep_id', 'token_id', 'secondary_struct'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_stride_ds = add_secondary_struct_column(merged_ds.take(10), stride_dir)\n",
    "mini_stride_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b0acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'values': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'structure_id': 'xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a',\n",
       "  'timestep_id': tensor(1),\n",
       "  'token_id': tensor(0),\n",
       "  'secondary_struct': None},\n",
       " {'values': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'structure_id': 'xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a',\n",
       "  'timestep_id': tensor(1),\n",
       "  'token_id': tensor(9),\n",
       "  'secondary_struct': 'E'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_stride_ds[0], mini_stride_ds[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44147071",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_ds_path = \"/home/wzarzecki/ds_secondary_struct/stride_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8399e4b3f9c740a0831c4ee7728de799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029d418d3c15415b9826d068f5ed39fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/28 shards):   0%|          | 0/732450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stride_ds = add_secondary_struct_column(merged_ds, stride_dir)\n",
    "stride_ds.save_to_disk(stride_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "312467a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a7e39e0a814713b33c2f992d3327a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861fb928cd4b418985b079219caf586d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/28 shards):   0%|          | 0/732450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def add_helix_column(ds: Dataset) -> Dataset:\n",
    "    \"\"\"\n",
    "    Adds a 'helix' column to the dataset based on the 'secondary_struct' column.\n",
    "    The 'helix' column is True if 'secondary_struct' is 'G', 'H', or 'I', otherwise False.\n",
    "    \"\"\"\n",
    "    helix_letters = {'G', 'H', 'I'}\n",
    "    def check_if_helix(example):\n",
    "        ss = example.get('secondary_struct')\n",
    "        return {'helix': ss is not None and ss in helix_letters}\n",
    "\n",
    "    return ds.map(check_if_helix)\n",
    "\n",
    "helix_ds = add_helix_column(stride_ds)\n",
    "helix_ds_path = \"/home/wzarzecki/ds_secondary_struct/helix_ds\"\n",
    "helix_ds.save_to_disk(helix_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17f3021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'values': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'structure_id': 'xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a',\n",
       "  'timestep_id': tensor(1),\n",
       "  'token_id': tensor(0),\n",
       "  'secondary_struct': None,\n",
       "  'helix': tensor(False)},\n",
       " {'values': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'structure_id': 'xxx_0_c4e8cf7d-8850-486c-8a9a-76f0b46a751a',\n",
       "  'timestep_id': tensor(1),\n",
       "  'token_id': tensor(48),\n",
       "  'secondary_struct': 'H',\n",
       "  'helix': tensor(True)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helix_ds[0], helix_ds[48]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffsae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
